discr_lr: 1e-4
model_lr: 1e-4
sgd_momentum: 0.9
batch_size: 2
discr_dropout_p: 0.
discr_acc_threshold: -1.

# Loss scaling values
lambda_seg: 1.
lambda_consis: 10.
lambda_discr: 0.001


cropbox: !!python/tuple [256, 256] #[480, 1204]
source_subset: 'train'
dataset_path_source: '/media/robin/Data/a2d2/camera_lidar_semantic/'  #'/var/datasets/feat_adapt_dataset/a2d2'
dataset_path_target: '/media/robin/Data/feat_adapt_dataset/cityscapes'  #'/var/datasets/feat_adapt_dataset/cityscapes'
train_log_file: 'train_log.txt'
# Backbone features: 512
# Output features: 19
discr_input_dim: 19

save_dir: 'exp2'
save_interval: 100

load_dir: 'exp2'
load_iter: 300

# backbone <-- UNTESTED
# output
adaption_level: 'output'

# feature
# struct
discriminator: 'struct'

# Miscellaneous parameters
print_interval: 1
num_workers: 1
