target_batch_size: 2  # Match 'per GPU' batchsize in MMSeg config
discr_dropout_p: 0.
discr_acc_threshold: -1.

# Loss scaling values
lambda_seg: 1.
lambda_consis: 10.
lambda_discr: 0.1

# Target dataset
#   'cityscapes' or 'a2d2'
target_dataset: 'a2d2'  #'a2d2'
# Absolute path to dataset root (untransformed)
#   ../a2d2/camera_lidar_semantic/
#   ../cityscapes/
target_dataset_path: '/media/robin/6E0806C1080687F3/a2d2_mini/camera_lidar_semantic'
# Crop box size matching SOURCE dataset
#   A2D2: [480, 1208]
#   Cityscapes: [512, 1024]
cropbox: !!python/tuple [512, 1024]

train_log_file: 'train_log.txt'
# Backbone features: 512
# Output features: 8
discr_input_dim: 8

eval_model: 'target'  # 'source' or 'target'

# backbone <-- UNTESTED
# output
adaption_level: 'output'

# feature
# struct
discriminator: 'struct'

# Miscellaneous parameters
num_workers: 1
